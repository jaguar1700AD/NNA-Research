{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implements weight sharing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "import numpy as np\n",
    "import  torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "import shutil\n",
    "import copy\n",
    "import pandas as pd\n",
    "from sklearn.cluster import KMeans, MiniBatchKMeans\n",
    "from statistics import mean\n",
    "from collections  import OrderedDict\n",
    "import sys\n",
    "\n",
    "device = torch.device('cuda')\n",
    "SAVE_PATH = 'D://models//wt_shared_net.pth'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = {\n",
    "    'train':transforms.Compose([\n",
    "        transforms.RandomResizedCrop(224), \n",
    "        transforms.RandomHorizontalFlip(), \n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406],[0.229,0.224,0.225])]),\n",
    "    'val': transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485,0.456,0.406],[0.229,0.224,0.225])])\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = 'D:\\\\datasets\\\\ILSVRC2012_img_val - Retrain\\\\'\n",
    "dataset = {x:datasets.ImageFolder(os.path.join(data_dir, x), transform[x]) for x in ['train', 'val']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = {x:torch.utils.data.DataLoader(dataset[x], batch_size = 512, shuffle = False, num_workers = 6, pin_memory=True)\n",
    "              for x in ['train', 'val']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size_actk = 24\n",
    "dataloader_actk = torch.utils.data.DataLoader(dataset['train'], batch_size = batch_size_actk, shuffle = True, num_workers = 6, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_size = {x:len(dataset[x]) for x in ['train', 'val']}\n",
    "class_names = dataset['train'].classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Quantize(nn.Module):\n",
    "    \n",
    "    global device\n",
    "    \n",
    "    def __init__(self, layer_type, wt_layer, num_vals, quick = False):\n",
    "        super(Quantize, self).__init__()\n",
    "        \n",
    "        if layer_type != 'conv' and layer_type != 'fc':\n",
    "            sys.exit(\"Invalid layer type given\")\n",
    "        \n",
    "        if quick == False:\n",
    "            self.mask = ~(wt_layer.weight == 0).to(device)\n",
    "            self.wt_shape = wt_layer.weight.shape\n",
    "            \n",
    "            mat = wt_layer.weight[self.mask]\n",
    "            flat_mat = mat.to('cpu').view(-1, 1).detach()\n",
    "            #kmeans = KMeans(n_clusters=num_vals, n_jobs=12)\n",
    "            kmeans = MiniBatchKMeans(n_clusters=num_vals, batch_size=1000000)\n",
    "            kmeans.fit(flat_mat)\n",
    "            \n",
    "            self.centroids = nn.Parameter(torch.from_numpy(kmeans.cluster_centers_).to(device).requires_grad_(True))\n",
    "            self.labels = nn.Parameter(torch.from_numpy(kmeans.labels_).to(device).view(mat.shape).type(torch.long), requires_grad=False)\n",
    "        else:\n",
    "            self.mask = ~(wt_layer.weight == 0).to(device)\n",
    "            mat = wt_layer.weight[self.mask]\n",
    "            self.wt_shape = wt_layer.weight.shape\n",
    "            self.centroids = nn.Parameter(torch.zeros((num_vals,1), device = device).requires_grad_(True))\n",
    "            self.labels = nn.Parameter(torch.zeros(mat.shape, dtype = torch.long, device = device), requires_grad=False)\n",
    "            \n",
    "        self.type = layer_type    \n",
    "        self.num_reps = num_vals\n",
    "        self.bias = wt_layer.bias.to(device).requires_grad_(True)\n",
    "        if layer_type == 'conv':\n",
    "            self.stride = wt_layer.stride\n",
    "            self.padding = wt_layer.padding\n",
    "            self.dilation = wt_layer.dilation\n",
    "            self.groups = wt_layer.groups\n",
    "        \n",
    "    def forward(self, x):\n",
    "        vals = torch.squeeze(self.centroids[self.labels], dim = -1).type(torch.float32)\n",
    "        wt = torch.zeros(self.wt_shape, dtype = torch.float32).to(device)\n",
    "        wt[self.mask] = vals\n",
    "        \n",
    "        if self.type == 'conv':\n",
    "            return F.conv2d(x, wt, bias = self.bias, stride = self.stride, padding = self.padding, dilation = self.dilation, groups = self.groups)\n",
    "        else:\n",
    "            return F.linear(x, wt, bias = self.bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AlexNet(nn.Module):\n",
    "\n",
    "    def __init__(self, init_model, quant_nums_w, quick = False, num_classes=1000):\n",
    "        super(AlexNet, self).__init__()\n",
    "        \n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, kernel_size=11, stride=4, padding=2),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "            nn.Conv2d(64, 192, kernel_size=5, padding=2),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "            nn.Conv2d(192, 384, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(384, 256, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(256, 256, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "        )\n",
    "        \n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n",
    "        \n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(256 * 6 * 6, 4096),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(4096, 4096),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(4096, num_classes),\n",
    "        )\n",
    "        \n",
    "        if init_model != None:\n",
    "            self.load_state_dict(copy.deepcopy(init_model.state_dict()))\n",
    "        \n",
    "        if quant_nums_w != None:\n",
    "            self.init_wt_quantizers(quant_nums_w, quick = quick)\n",
    "       \n",
    "    def init_wt_quantizers(self, quant_nums, quick):\n",
    "        \n",
    "        ind = -1\n",
    "        \n",
    "        q_list = []\n",
    "        for layer in self.features:\n",
    "            if isinstance(layer, nn.Conv2d):\n",
    "                ind += 1\n",
    "                q_list.append(Quantize('conv', layer, quant_nums[ind], quick))\n",
    "                print('Done', ind)\n",
    "            else:\n",
    "                q_list.append(layer)\n",
    "        self.features = nn.Sequential(*q_list)\n",
    "        \n",
    "        q_list = []\n",
    "        for layer in self.classifier:\n",
    "            if isinstance(layer, nn.Linear):\n",
    "                ind += 1\n",
    "                q_list.append(Quantize('fc', layer, quant_nums[ind], quick))\n",
    "                print('Done', ind)\n",
    "            else:\n",
    "                q_list.append(layer)\n",
    "        self.classifier = nn.Sequential(*q_list)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = self.avgpool(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.classifier(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_accuracy(model, phase, record_grad, criterion = None, optimizer = None, I = None):\n",
    "    \n",
    "    global device\n",
    "    \n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "#     if record_grad:\n",
    "#         model.train()\n",
    "#     else:\n",
    "#         model.eval()\n",
    "\n",
    "        \n",
    "    done = 0\n",
    "    acc = 0.0\n",
    "    since = time.time()\n",
    "    corrects = torch.tensor(0)\n",
    "    total_loss = 0.0\n",
    "    corrects = corrects.to(device)\n",
    "    loss = 100.0\n",
    "    \n",
    "    if I == None:\n",
    "        for inputs, labels in dataloader[phase]:\n",
    "\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            if record_grad:\n",
    "                with torch.set_grad_enabled(True):\n",
    "                    optimizer.zero_grad()\n",
    "                    outputs = model(inputs)\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "                    corrects += torch.sum(preds == labels)\n",
    "                    loss = criterion(outputs, labels)\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "\n",
    "                total_loss += loss.item() * inputs.size(0)\n",
    "\n",
    "            else:\n",
    "                with torch.set_grad_enabled(False):\n",
    "                    outputs = model(inputs)\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "                    corrects += torch.sum(preds == labels)\n",
    "                    \n",
    "            done += len(inputs)\n",
    "            print('\\r{}, {}, {:.2f}%, {:.2f}'.format(corrects.item(), done, corrects.item() * 100.0 / done, total_loss), end = '')\n",
    "#             if done >= 64:\n",
    "#                 break\n",
    "                    \n",
    "    else:\n",
    "            \n",
    "        inputs, labels = I\n",
    "\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        if record_grad:\n",
    "            with torch.set_grad_enabled(True):\n",
    "                optimizer.zero_grad()\n",
    "                outputs = model(inputs)\n",
    "                _, preds = torch.max(outputs, 1)\n",
    "                corrects += torch.sum(preds == labels)\n",
    "                loss = criterion(outputs, labels)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                #print(model.features[0].centroids.grad)\n",
    "            total_loss += loss.item() * inputs.size(0)\n",
    "\n",
    "        else:\n",
    "            with torch.set_grad_enabled(False):\n",
    "                outputs = model(inputs)\n",
    "                _, preds = torch.max(outputs, 1)\n",
    "                corrects += torch.sum(preds == labels)\n",
    "                \n",
    "        done += len(inputs)\n",
    "        print('\\r{}, {}, {:.2f}%, {:.2f}'.format(corrects.item(), done, corrects.item() * 100.0 / done, total_loss), end = '')\n",
    "\n",
    "    acc = corrects.double() / done\n",
    "    print('\\n{} Acc: {:.4f} %'.format(phase, acc * 100))\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print('Total time taken = {} seconds'.format(time_elapsed))\n",
    "\n",
    "    if record_grad:\n",
    "        return acc, total_loss\n",
    "    else:\n",
    "        return acc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, criterion, optimizer, scheduler = None, num_epochs = 25, I = None, do_baseline = True):\n",
    "    \n",
    "    global device\n",
    "    \n",
    "    print('          ', end = '\\r')\n",
    "    acc = {'train':0.0, 'val':0.0}\n",
    "    best_acc = 0.0\n",
    "    \n",
    "    if do_baseline:\n",
    "        acc['val'] = check_accuracy(model, phase = 'val', record_grad = False)\n",
    "        acc['train'] = check_accuracy(model, phase = 'train', record_grad = False)\n",
    "        print('.......... Baseline Evaluation Done ..............')\n",
    "        best_acc = acc['val']\n",
    "    \n",
    "    since = time.time()\n",
    "    torch.save(model.state_dict(), SAVE_PATH)\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "        print('-' * 10)\n",
    "        \n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'val':\n",
    "                epoch_acc = check_accuracy(model, phase, record_grad = False, I = I)\n",
    "                if epoch_acc > best_acc:\n",
    "                    print('Saving')\n",
    "                    best_acc = epoch_acc\n",
    "                    torch.save(model.state_dict(), SAVE_PATH)\n",
    "            else:\n",
    "                epoch_acc, epoch_loss = check_accuracy(model, phase, criterion=criterion, optimizer=optimizer, record_grad = True, I = I)\n",
    "                \n",
    "        print()\n",
    "        \n",
    "        if scheduler != None:\n",
    "            scheduler.step()\n",
    "        \n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n",
    "    print('Best val Acc: {:4f}'.format(best_acc))\n",
    "    \n",
    "    model.load_state_dict(torch.load(SAVE_PATH))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda')\n",
    "alexnet = models.alexnet(pretrained=True)\n",
    "alexnet.load_state_dict(torch.load('D://models//undone_pruned_net.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = alexnet\n",
    "# model.to(device)\n",
    "# check_accuracy(model, 'val', record_grad = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done 0\n",
      "Done 1\n",
      "Done 2\n",
      "Done 3\n",
      "Done 4\n",
      "Done 5\n",
      "Done 6\n",
      "Done 7\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ORIG_PATH = 'D://models//NNA_quants.pth'\n",
    "\n",
    "# model = AlexNet(init_model=alexnet, quant_nums_w = [32]*8, quick = False)\n",
    "# torch.save(model.state_dict(), ORIG_PATH)\n",
    "\n",
    "model = AlexNet(init_model=alexnet, quant_nums_w = [32]*8, quick = True)\n",
    "# model.load_state_dict(torch.load(ORIG_PATH))\n",
    "model.load_state_dict(torch.load(SAVE_PATH))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8 [Parameter containing:\n",
      "tensor([[ 0.0474],\n",
      "        [-0.1279],\n",
      "        [ 0.2761],\n",
      "        [-0.3138],\n",
      "        [-0.0402],\n",
      "        [ 0.1549],\n",
      "        [ 0.6490],\n",
      "        [-0.2235],\n",
      "        [-0.4541],\n",
      "        [ 0.0802],\n",
      "        [ 0.3952],\n",
      "        [-0.0605],\n",
      "        [ 0.0207],\n",
      "        [ 0.2302],\n",
      "        [-0.1868],\n",
      "        [-0.6518],\n",
      "        [-0.0209],\n",
      "        [ 0.1002],\n",
      "        [ 0.1255],\n",
      "        [-0.0826],\n",
      "        [-0.3815],\n",
      "        [ 0.5585],\n",
      "        [ 0.3306],\n",
      "        [-0.2637],\n",
      "        [-0.1040],\n",
      "        [ 0.0620],\n",
      "        [ 0.1894],\n",
      "        [-0.1548],\n",
      "        [ 0.0339],\n",
      "        [ 0.4757],\n",
      "        [ 0.8451],\n",
      "        [-0.5259]], device='cuda:0', requires_grad=True), Parameter containing:\n",
      "tensor([[-0.0397],\n",
      "        [ 0.0343],\n",
      "        [-0.2697],\n",
      "        [ 0.2221],\n",
      "        [-0.1401],\n",
      "        [ 0.0945],\n",
      "        [ 0.0174],\n",
      "        [-0.0168],\n",
      "        [-0.0845],\n",
      "        [ 2.1282],\n",
      "        [ 0.4799],\n",
      "        [ 0.0580],\n",
      "        [ 0.1466],\n",
      "        [-0.0313],\n",
      "        [-0.3692],\n",
      "        [-0.0598],\n",
      "        [-0.2100],\n",
      "        [-0.1184],\n",
      "        [ 0.0747],\n",
      "        [ 0.3654],\n",
      "        [-0.5998],\n",
      "        [ 0.0256],\n",
      "        [-0.1002],\n",
      "        [ 0.0452],\n",
      "        [-0.0236],\n",
      "        [-0.1691],\n",
      "        [ 0.2809],\n",
      "        [ 0.6917],\n",
      "        [-0.0498],\n",
      "        [ 0.1186],\n",
      "        [-0.0712],\n",
      "        [ 0.1799]], device='cuda:0', requires_grad=True), Parameter containing:\n",
      "tensor([[ 0.0163],\n",
      "        [-0.0319],\n",
      "        [ 0.0670],\n",
      "        [-0.0889],\n",
      "        [ 0.0448],\n",
      "        [-0.0643],\n",
      "        [ 0.2091],\n",
      "        [-0.0209],\n",
      "        [-0.1258],\n",
      "        [-0.0438],\n",
      "        [ 0.0292],\n",
      "        [ 0.1171],\n",
      "        [-0.2431],\n",
      "        [ 0.3168],\n",
      "        [ 0.0805],\n",
      "        [-0.0750],\n",
      "        [-0.1530],\n",
      "        [ 0.0549],\n",
      "        [ 0.1507],\n",
      "        [-0.0162],\n",
      "        [ 0.5327],\n",
      "        [-0.0499],\n",
      "        [ 0.0228],\n",
      "        [-0.3315],\n",
      "        [-0.1053],\n",
      "        [-0.0378],\n",
      "        [ 0.0365],\n",
      "        [-0.1898],\n",
      "        [ 0.0958],\n",
      "        [-0.0263],\n",
      "        [-0.0564],\n",
      "        [-0.6214]], device='cuda:0', requires_grad=True), Parameter containing:\n",
      "tensor([[ 0.0556],\n",
      "        [-0.0351],\n",
      "        [ 0.0246],\n",
      "        [-0.0203],\n",
      "        [-0.0740],\n",
      "        [-0.0560],\n",
      "        [ 0.0940],\n",
      "        [ 0.0201],\n",
      "        [ 0.0487],\n",
      "        [ 0.0378],\n",
      "        [-0.1514],\n",
      "        [ 0.1494],\n",
      "        [-0.0279],\n",
      "        [-0.0437],\n",
      "        [-0.1082],\n",
      "        [-0.0158],\n",
      "        [ 0.1154],\n",
      "        [ 0.0159],\n",
      "        [ 0.0803],\n",
      "        [-0.0493],\n",
      "        [-0.2318],\n",
      "        [ 0.0291],\n",
      "        [ 0.0428],\n",
      "        [-0.0240],\n",
      "        [ 0.0629],\n",
      "        [-0.0640],\n",
      "        [-0.0390],\n",
      "        [-0.0314],\n",
      "        [ 0.2117],\n",
      "        [-0.0870],\n",
      "        [ 0.0334],\n",
      "        [ 0.0705]], device='cuda:0', requires_grad=True), Parameter containing:\n",
      "tensor([[-0.0256],\n",
      "        [ 0.0371],\n",
      "        [-0.0747],\n",
      "        [-0.0563],\n",
      "        [ 0.0196],\n",
      "        [ 0.0538],\n",
      "        [-0.0191],\n",
      "        [-0.0368],\n",
      "        [ 0.0914],\n",
      "        [ 0.0477],\n",
      "        [ 0.0280],\n",
      "        [-0.0457],\n",
      "        [-0.1379],\n",
      "        [ 0.0694],\n",
      "        [ 0.0157],\n",
      "        [ 0.1610],\n",
      "        [-0.0643],\n",
      "        [-0.0157],\n",
      "        [-0.0881],\n",
      "        [-0.0327],\n",
      "        [ 0.0239],\n",
      "        [-0.0413],\n",
      "        [ 0.1248],\n",
      "        [-0.0222],\n",
      "        [ 0.0797],\n",
      "        [-0.0290],\n",
      "        [ 0.0325],\n",
      "        [ 0.0423],\n",
      "        [-0.0505],\n",
      "        [ 0.0608],\n",
      "        [-0.1064],\n",
      "        [ 0.1054]], device='cuda:0', requires_grad=True), Parameter containing:\n",
      "tensor([[-0.0152],\n",
      "        [ 0.0181],\n",
      "        [-0.0201],\n",
      "        [ 0.0283],\n",
      "        [-0.0310],\n",
      "        [ 0.0214],\n",
      "        [ 0.0142],\n",
      "        [-0.0183],\n",
      "        [-0.0245],\n",
      "        [ 0.0243],\n",
      "        [-0.0168],\n",
      "        [ 0.0349],\n",
      "        [ 0.0201],\n",
      "        [-0.0415],\n",
      "        [-0.0264],\n",
      "        [ 0.0166],\n",
      "        [-0.0221],\n",
      "        [-0.0161],\n",
      "        [ 0.0310],\n",
      "        [ 0.0228],\n",
      "        [-0.0346],\n",
      "        [-0.0191],\n",
      "        [ 0.0261],\n",
      "        [ 0.0191],\n",
      "        [ 0.0410],\n",
      "        [-0.0176],\n",
      "        [-0.0285],\n",
      "        [ 0.0159],\n",
      "        [-0.0138],\n",
      "        [ 0.0173],\n",
      "        [-0.0212],\n",
      "        [-0.0231]], device='cuda:0', requires_grad=True), Parameter containing:\n",
      "tensor([[-0.0248],\n",
      "        [ 0.0161],\n",
      "        [ 0.0266],\n",
      "        [-0.0166],\n",
      "        [ 0.0382],\n",
      "        [-0.0317],\n",
      "        [ 0.0209],\n",
      "        [-0.0217],\n",
      "        [-0.0194],\n",
      "        [ 0.0318],\n",
      "        [-0.0131],\n",
      "        [ 0.0182],\n",
      "        [-0.0381],\n",
      "        [-0.0290],\n",
      "        [-0.0431],\n",
      "        [ 0.0505],\n",
      "        [-0.0205],\n",
      "        [ 0.0244],\n",
      "        [-0.0157],\n",
      "        [ 0.0291],\n",
      "        [-0.0174],\n",
      "        [-0.0232],\n",
      "        [ 0.0131],\n",
      "        [-0.0534],\n",
      "        [ 0.0429],\n",
      "        [ 0.0347],\n",
      "        [ 0.0170],\n",
      "        [ 0.0194],\n",
      "        [-0.0267],\n",
      "        [ 0.0224],\n",
      "        [-0.0184],\n",
      "        [-0.0347]], device='cuda:0', requires_grad=True), Parameter containing:\n",
      "tensor([[-0.0243],\n",
      "        [ 0.0262],\n",
      "        [ 0.0527],\n",
      "        [-0.0174],\n",
      "        [ 0.0131],\n",
      "        [ 0.0784],\n",
      "        [-0.0357],\n",
      "        [ 0.0391],\n",
      "        [-0.0400],\n",
      "        [ 0.0206],\n",
      "        [-0.0657],\n",
      "        [ 0.1321],\n",
      "        [ 0.0641],\n",
      "        [ 0.0320],\n",
      "        [-0.0530],\n",
      "        [-0.0295],\n",
      "        [-0.0136],\n",
      "        [-0.0218],\n",
      "        [ 0.0432],\n",
      "        [ 0.0176],\n",
      "        [ 0.0886],\n",
      "        [ 0.0582],\n",
      "        [-0.0456],\n",
      "        [-0.0324],\n",
      "        [ 0.0235],\n",
      "        [ 0.1035],\n",
      "        [-0.0196],\n",
      "        [ 0.0705],\n",
      "        [ 0.0353],\n",
      "        [-0.0268],\n",
      "        [ 0.0291],\n",
      "        [ 0.0479]], device='cuda:0', requires_grad=True)]\n"
     ]
    }
   ],
   "source": [
    "params = list(filter(lambda p: p.requires_grad, model.parameters()))\n",
    "print(len(params), params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5397, 10000, 53.97%, 0.00\n",
      "val Acc: 53.9700 %\n",
      "Total time taken = 34.36496663093567 seconds\n",
      "12901, 27648, 46.66%, 0.00"
     ]
    }
   ],
   "source": [
    "model.to(device)\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "criterion = nn.CrossEntropyLoss() \n",
    "params = filter(lambda p: p.requires_grad, model.parameters())\n",
    "optimizer = optim.SGD(params, lr = 1e-8, momentum = 0.9)\n",
    "#exp_lr_scheduler = lr_scheduler.StepLR(optimizer, step_size = 5, gamma = 0.5)\n",
    "exp_lr_scheduler = None\n",
    "#I = next(iter(dataloader['train']))\n",
    "I = None\n",
    "\n",
    "model = train(model, criterion, optimizer, exp_lr_scheduler, num_epochs = 100, I = I, do_baseline = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####################################################################################################################\n",
    "####################################################################################################################\n",
    "####################################################################################################################\n",
    "####################################################################################################################\n",
    "####################################################################################################################\n",
    "####################################################################################################################\n",
    "####################################################################################################################\n",
    "####################################################################################################################\n",
    "####################################################################################################################\n",
    "####################################################################################################################"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
