{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implements weight sharing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "import numpy as np\n",
    "import  torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "import shutil\n",
    "import copy\n",
    "import pandas as pd\n",
    "from sklearn.cluster import KMeans, MiniBatchKMeans\n",
    "from statistics import mean\n",
    "from collections  import OrderedDict\n",
    "import sys\n",
    "\n",
    "device = torch.device('cuda')\n",
    "SAVE_PATH = 'D://models//wt_shared_net.pth'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = {\n",
    "    'train':transforms.Compose([\n",
    "        transforms.RandomResizedCrop(224), \n",
    "        transforms.RandomHorizontalFlip(), \n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406],[0.229,0.224,0.225])]),\n",
    "    'val': transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485,0.456,0.406],[0.229,0.224,0.225])])\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = 'D:\\\\datasets\\\\ILSVRC2012_img_val - Retrain\\\\'\n",
    "dataset = {x:datasets.ImageFolder(os.path.join(data_dir, x), transform[x]) for x in ['train', 'val']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = {x:torch.utils.data.DataLoader(dataset[x], batch_size = 512, shuffle = False, num_workers = 6, pin_memory=True)\n",
    "              for x in ['train', 'val']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size_actk = 24\n",
    "dataloader_actk = torch.utils.data.DataLoader(dataset['train'], batch_size = batch_size_actk, shuffle = True, num_workers = 6, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_size = {x:len(dataset[x]) for x in ['train', 'val']}\n",
    "class_names = dataset['train'].classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Quantize(nn.Module):\n",
    "    \n",
    "    global device\n",
    "    \n",
    "    def __init__(self, layer_type, wt_layer, num_vals, quick = False):\n",
    "        super(Quantize, self).__init__()\n",
    "        \n",
    "        if layer_type != 'conv' and layer_type != 'fc':\n",
    "            sys.exit(\"Invalid layer type given\")\n",
    "        \n",
    "        if quick == False:\n",
    "            self.mask = ~(wt_layer.weight == 0).to(device)\n",
    "            self.wt_shape = wt_layer.weight.shape\n",
    "            \n",
    "            mat = wt_layer.weight[self.mask]\n",
    "            flat_mat = mat.to('cpu').view(-1, 1).detach()\n",
    "            #kmeans = KMeans(n_clusters=num_vals, n_jobs=12)\n",
    "            kmeans = MiniBatchKMeans(n_clusters=num_vals, batch_size=1000000)\n",
    "            kmeans.fit(flat_mat)\n",
    "            \n",
    "            self.centroids = nn.Parameter(torch.from_numpy(kmeans.cluster_centers_).to(device).requires_grad_(True))\n",
    "            self.labels = nn.Parameter(torch.from_numpy(kmeans.labels_).to(device).view(mat.shape).type(torch.long), requires_grad=False)\n",
    "        else:\n",
    "            self.mask = ~(wt_layer.weight == 0).to(device)\n",
    "            mat = wt_layer.weight[self.mask]\n",
    "            self.wt_shape = wt_layer.weight.shape\n",
    "            self.centroids = nn.Parameter(torch.zeros((num_vals,1), device = device).requires_grad_(True))\n",
    "            self.labels = nn.Parameter(torch.zeros(mat.shape, dtype = torch.long, device = device), requires_grad=False)\n",
    "            \n",
    "        self.type = layer_type    \n",
    "        self.num_reps = num_vals\n",
    "        self.bias = wt_layer.bias.to(device).requires_grad_(True)\n",
    "        if layer_type == 'conv':\n",
    "            self.stride = wt_layer.stride\n",
    "            self.padding = wt_layer.padding\n",
    "            self.dilation = wt_layer.dilation\n",
    "            self.groups = wt_layer.groups\n",
    "        \n",
    "    def forward(self, x):\n",
    "        vals = torch.squeeze(self.centroids[self.labels], dim = -1).type(torch.float32)\n",
    "        wt = torch.zeros(self.wt_shape, dtype = torch.float32).to(device)\n",
    "        wt[self.mask] = vals\n",
    "        \n",
    "        if self.type == 'conv':\n",
    "            return F.conv2d(x, wt, bias = self.bias, stride = self.stride, padding = self.padding, dilation = self.dilation, groups = self.groups)\n",
    "        else:\n",
    "            return F.linear(x, wt, bias = self.bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AlexNet(nn.Module):\n",
    "\n",
    "    def __init__(self, init_model, quant_nums_w, quick = False, num_classes=1000):\n",
    "        super(AlexNet, self).__init__()\n",
    "        \n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, kernel_size=11, stride=4, padding=2),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "            nn.Conv2d(64, 192, kernel_size=5, padding=2),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "            nn.Conv2d(192, 384, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(384, 256, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(256, 256, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "        )\n",
    "        \n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n",
    "        \n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(256 * 6 * 6, 4096),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(4096, 4096),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(4096, num_classes),\n",
    "        )\n",
    "        \n",
    "        if init_model != None:\n",
    "            self.load_state_dict(copy.deepcopy(init_model.state_dict()))\n",
    "        \n",
    "        if quant_nums_w != None:\n",
    "            self.init_wt_quantizers(quant_nums_w, quick = quick)\n",
    "       \n",
    "    def init_wt_quantizers(self, quant_nums, quick):\n",
    "        \n",
    "        ind = -1\n",
    "        \n",
    "        q_list = []\n",
    "        for layer in self.features:\n",
    "            if isinstance(layer, nn.Conv2d):\n",
    "                ind += 1\n",
    "                q_list.append(Quantize('conv', layer, quant_nums[ind], quick))\n",
    "                print('Done', ind)\n",
    "            else:\n",
    "                q_list.append(layer)\n",
    "        self.features = nn.Sequential(*q_list)\n",
    "        \n",
    "        q_list = []\n",
    "        for layer in self.classifier:\n",
    "            if isinstance(layer, nn.Linear):\n",
    "                ind += 1\n",
    "                q_list.append(Quantize('fc', layer, quant_nums[ind], quick))\n",
    "                print('Done', ind)\n",
    "            else:\n",
    "                q_list.append(layer)\n",
    "        self.classifier = nn.Sequential(*q_list)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = self.avgpool(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "    \n",
    "    def un_quantize(self):\n",
    "        q_list = []\n",
    "        for layer in self.features:\n",
    "            if isinstance(layer, Quantize):\n",
    "                vals = torch.squeeze(layer.centroids[layer.labels], dim = -1).type(torch.float32)\n",
    "                wt = torch.zeros(layer.wt_shape, dtype = torch.float32).to(device)\n",
    "                wt[layer.mask] = vals\n",
    "                my_layer = nn.Conv2d(wt.shape[1], wt.shape[0], kernel_size = wt.shape[2], stride = layer.stride, padding = layer.padding, dilation = layer.dilation, groups = layer.groups)\n",
    "                my_layer.weight.data.copy_(wt)\n",
    "                my_layer.bias.data.copy_(layer.bias)\n",
    "                q_list.append(my_layer)\n",
    "            else:\n",
    "                q_list.append(layer)\n",
    "        self.features = nn.Sequential(*q_list)\n",
    "        \n",
    "        q_list = []\n",
    "        for layer in self.classifier:\n",
    "            if isinstance(layer, Quantize):\n",
    "                vals = torch.squeeze(layer.centroids[layer.labels], dim = -1).type(torch.float32)\n",
    "                wt = torch.zeros(layer.wt_shape, dtype = torch.float32).to(device)\n",
    "                wt[layer.mask] = vals\n",
    "                my_layer = nn.Linear(wt.shape[1], wt.shape[0])\n",
    "                my_layer.weight.data.copy_(wt)\n",
    "                my_layer.bias.data.copy_(layer.bias)\n",
    "                q_list.append(my_layer)\n",
    "            else:\n",
    "                q_list.append(layer)\n",
    "        self.classifier = nn.Sequential(*q_list)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_accuracy(model, phase, record_grad, criterion = None, optimizer = None, I = None):\n",
    "    \n",
    "    global device\n",
    "    \n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "#     if record_grad:\n",
    "#         model.train()\n",
    "#     else:\n",
    "#         model.eval()\n",
    "\n",
    "        \n",
    "    done = 0\n",
    "    acc = 0.0\n",
    "    since = time.time()\n",
    "    corrects = torch.tensor(0)\n",
    "    total_loss = 0.0\n",
    "    corrects = corrects.to(device)\n",
    "    loss = 100.0\n",
    "    \n",
    "    if I == None:\n",
    "        for inputs, labels in dataloader[phase]:\n",
    "\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            if record_grad:\n",
    "                with torch.set_grad_enabled(True):\n",
    "                    optimizer.zero_grad()\n",
    "                    outputs = model(inputs)\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "                    corrects += torch.sum(preds == labels)\n",
    "                    loss = criterion(outputs, labels)\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "\n",
    "                total_loss += loss.item() * inputs.size(0)\n",
    "\n",
    "            else:\n",
    "                with torch.set_grad_enabled(False):\n",
    "                    outputs = model(inputs)\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "                    corrects += torch.sum(preds == labels)\n",
    "                    \n",
    "            done += len(inputs)\n",
    "            print('\\r{}, {}, {:.2f}%, {:.2f}'.format(corrects.item(), done, corrects.item() * 100.0 / done, total_loss), end = '')\n",
    "#             if done >= 64:\n",
    "#                 break\n",
    "                    \n",
    "    else:\n",
    "            \n",
    "        inputs, labels = I\n",
    "\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        if record_grad:\n",
    "            with torch.set_grad_enabled(True):\n",
    "                optimizer.zero_grad()\n",
    "                outputs = model(inputs)\n",
    "                _, preds = torch.max(outputs, 1)\n",
    "                corrects += torch.sum(preds == labels)\n",
    "                loss = criterion(outputs, labels)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                #print(model.features[0].centroids.grad)\n",
    "            total_loss += loss.item() * inputs.size(0)\n",
    "\n",
    "        else:\n",
    "            with torch.set_grad_enabled(False):\n",
    "                outputs = model(inputs)\n",
    "                _, preds = torch.max(outputs, 1)\n",
    "                corrects += torch.sum(preds == labels)\n",
    "                \n",
    "        done += len(inputs)\n",
    "        print('\\r{}, {}, {:.2f}%, {:.2f}'.format(corrects.item(), done, corrects.item() * 100.0 / done, total_loss), end = '')\n",
    "\n",
    "    acc = corrects.double() / done\n",
    "    print('\\n{} Acc: {:.4f} %'.format(phase, acc * 100))\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print('Total time taken = {} seconds'.format(time_elapsed))\n",
    "\n",
    "    if record_grad:\n",
    "        return acc, total_loss\n",
    "    else:\n",
    "        return acc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, criterion, optimizer, scheduler = None, num_epochs = 25, I = None, do_baseline = True):\n",
    "    \n",
    "    global device\n",
    "    \n",
    "    print('          ', end = '\\r')\n",
    "    acc = {'train':0.0, 'val':0.0}\n",
    "    best_acc = 0.0\n",
    "    \n",
    "    if do_baseline:\n",
    "        acc['val'] = check_accuracy(model, phase = 'val', record_grad = False)\n",
    "        acc['train'] = check_accuracy(model, phase = 'train', record_grad = False)\n",
    "        print('.......... Baseline Evaluation Done ..............')\n",
    "        best_acc = acc['val']\n",
    "    \n",
    "    since = time.time()\n",
    "    torch.save(model.state_dict(), SAVE_PATH)\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "        print('-' * 10)\n",
    "        \n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'val':\n",
    "                epoch_acc = check_accuracy(model, phase, record_grad = False, I = I)\n",
    "                if epoch_acc > best_acc:\n",
    "                    print('Saving')\n",
    "                    best_acc = epoch_acc\n",
    "                    torch.save(model.state_dict(), SAVE_PATH)\n",
    "            else:\n",
    "                epoch_acc, epoch_loss = check_accuracy(model, phase, criterion=criterion, optimizer=optimizer, record_grad = True, I = I)\n",
    "                \n",
    "        print()\n",
    "        \n",
    "        if scheduler != None:\n",
    "            scheduler.step()\n",
    "        \n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n",
    "    print('Best val Acc: {:4f}'.format(best_acc))\n",
    "    \n",
    "    model.load_state_dict(torch.load(SAVE_PATH))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda')\n",
    "alexnet = models.alexnet(pretrained=True)\n",
    "alexnet.load_state_dict(torch.load('D://models//undone_pruned_net.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = alexnet\n",
    "# model.to(device)\n",
    "# check_accuracy(model, 'val', record_grad = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done 0\n",
      "Done 1\n",
      "Done 2\n",
      "Done 3\n",
      "Done 4\n",
      "Done 5\n",
      "Done 6\n",
      "Done 7\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ORIG_PATH = 'D://models//NNA_quants.pth'\n",
    "\n",
    "# model = AlexNet(init_model=alexnet, quant_nums_w = [32]*8, quick = False)\n",
    "# torch.save(model.state_dict(), ORIG_PATH)\n",
    "\n",
    "model = AlexNet(init_model=alexnet, quant_nums_w = [32]*8, quick = True)\n",
    "# model.load_state_dict(torch.load(ORIG_PATH))\n",
    "model.load_state_dict(torch.load(SAVE_PATH))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = list(filter(lambda p: p.requires_grad, model.parameters()))\n",
    "print(len(params), params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.to(device)\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "criterion = nn.CrossEntropyLoss() \n",
    "params = filter(lambda p: p.requires_grad, model.parameters())\n",
    "optimizer = optim.SGD(params, lr = 1e-9, momentum = 0.9)\n",
    "#exp_lr_scheduler = lr_scheduler.StepLR(optimizer, step_size = 5, gamma = 0.5)\n",
    "exp_lr_scheduler = None\n",
    "#I = next(iter(dataloader['train']))\n",
    "I = None\n",
    "\n",
    "model = train(model, criterion, optimizer, exp_lr_scheduler, num_epochs = 100, I = I, do_baseline = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.un_quantize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Conv2d(3, 64, kernel_size=(11, 11), stride=(4, 4), padding=(2, 2))\n",
       "  (1): ReLU(inplace=True)\n",
       "  (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (3): Conv2d(64, 192, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "  (4): ReLU(inplace=True)\n",
       "  (5): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (6): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (7): ReLU(inplace=True)\n",
       "  (8): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (9): ReLU(inplace=True)\n",
       "  (10): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (11): ReLU(inplace=True)\n",
       "  (12): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       ")"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Dropout(p=0.5, inplace=False)\n",
       "  (1): Linear(in_features=9216, out_features=4096, bias=True)\n",
       "  (2): ReLU(inplace=True)\n",
       "  (3): Dropout(p=0.5, inplace=False)\n",
       "  (4): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "  (5): ReLU(inplace=True)\n",
       "  (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.to(device)\n",
    "check_accuracy(model, 'val', record_grad = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####################################################################################################################\n",
    "####################################################################################################################\n",
    "####################################################################################################################\n",
    "####################################################################################################################\n",
    "####################################################################################################################\n",
    "####################################################################################################################\n",
    "####################################################################################################################\n",
    "####################################################################################################################\n",
    "####################################################################################################################\n",
    "####################################################################################################################"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
