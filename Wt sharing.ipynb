{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implements weight sharing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "import numpy as np\n",
    "import  torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "import shutil\n",
    "import copy\n",
    "from sklearn.cluster import KMeans, MiniBatchKMeans\n",
    "from statistics import mean\n",
    "from collections  import OrderedDict\n",
    "import sys\n",
    "\n",
    "device = torch.device('cuda')\n",
    "SAVE_PATH = '../models/wt_shared_net.pth'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = {\n",
    "    'train':transforms.Compose([\n",
    "        transforms.RandomResizedCrop(224), \n",
    "        transforms.RandomHorizontalFlip(), \n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406],[0.229,0.224,0.225])]),\n",
    "    'val': transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485,0.456,0.406],[0.229,0.224,0.225])])\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = '../datasets/ILSVRC2012_img_val - Retrain/'\n",
    "dataset = {x:datasets.ImageFolder(os.path.join(data_dir, x), transform[x]) for x in ['train', 'val']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = {x:torch.utils.data.DataLoader(dataset[x], batch_size = 512, shuffle = False, num_workers = 16, pin_memory=True)\n",
    "              for x in ['train', 'val']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size_actk = 24\n",
    "dataloader_actk = torch.utils.data.DataLoader(dataset['train'], batch_size = batch_size_actk, shuffle = True, num_workers = 6, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_size = {x:len(dataset[x]) for x in ['train', 'val']}\n",
    "class_names = dataset['train'].classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Quantize(nn.Module):\n",
    "    \n",
    "    global device\n",
    "    \n",
    "    def __init__(self, layer_type, wt_layer, num_vals, quick = False):\n",
    "        super(Quantize, self).__init__()\n",
    "        \n",
    "        if layer_type != 'conv' and layer_type != 'fc':\n",
    "            sys.exit(\"Invalid layer type given\")\n",
    "        \n",
    "        if quick == False:\n",
    "            self.mask = ~(wt_layer.weight == 0).to(device)\n",
    "            self.wt_shape = wt_layer.weight.shape\n",
    "            \n",
    "            mat = wt_layer.weight[self.mask]\n",
    "            flat_mat = mat.to('cpu').view(-1, 1).detach()\n",
    "            #kmeans = KMeans(n_clusters=num_vals, n_jobs=12)\n",
    "            kmeans = MiniBatchKMeans(n_clusters=num_vals, batch_size=5000000)\n",
    "            kmeans.fit(flat_mat)\n",
    "            \n",
    "            self.centroids = nn.Parameter(torch.from_numpy(kmeans.cluster_centers_).to(device).requires_grad_(True))\n",
    "            self.labels = nn.Parameter(torch.from_numpy(kmeans.labels_).to(device).view(mat.shape).type(torch.long), requires_grad=False)\n",
    "        else:\n",
    "            self.mask = ~(wt_layer.weight == 0).to(device)\n",
    "            mat = wt_layer.weight[self.mask]\n",
    "            self.wt_shape = wt_layer.weight.shape\n",
    "            self.centroids = nn.Parameter(torch.zeros((num_vals,1), device = device).requires_grad_(True))\n",
    "            self.labels = nn.Parameter(torch.zeros(mat.shape, dtype = torch.long, device = device), requires_grad=False)\n",
    "            \n",
    "        self.type = layer_type    \n",
    "        self.num_reps = num_vals\n",
    "        self.bias = wt_layer.bias.to(device).requires_grad_(True)\n",
    "        if layer_type == 'conv':\n",
    "            self.stride = wt_layer.stride\n",
    "            self.padding = wt_layer.padding\n",
    "            self.dilation = wt_layer.dilation\n",
    "            self.groups = wt_layer.groups\n",
    "        \n",
    "    def forward(self, x):\n",
    "        vals = torch.squeeze(self.centroids[self.labels], dim = -1).type(torch.float32)\n",
    "        wt = torch.zeros(self.wt_shape, dtype = torch.float32).to(device)\n",
    "        wt[self.mask] = vals\n",
    "        \n",
    "        if self.type == 'conv':\n",
    "            return F.conv2d(x, wt, bias = self.bias, stride = self.stride, padding = self.padding, dilation = self.dilation, groups = self.groups)\n",
    "        else:\n",
    "            return F.linear(x, wt, bias = self.bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AlexNet(nn.Module):\n",
    "\n",
    "    def __init__(self, init_model, quant_nums_w, quick = False, num_classes=1000):\n",
    "        super(AlexNet, self).__init__()\n",
    "        \n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, kernel_size=11, stride=4, padding=2),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "            nn.Conv2d(64, 192, kernel_size=5, padding=2),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "            nn.Conv2d(192, 384, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(384, 256, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(256, 256, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "        )\n",
    "        \n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n",
    "        \n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(256 * 6 * 6, 4096),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(4096, 4096),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(4096, num_classes),\n",
    "        )\n",
    "        \n",
    "        if init_model != None:\n",
    "            self.load_state_dict(copy.deepcopy(init_model.state_dict()))\n",
    "        \n",
    "        if quant_nums_w != None:\n",
    "            self.init_wt_quantizers(quant_nums_w, quick = quick)\n",
    "       \n",
    "    def init_wt_quantizers(self, quant_nums, quick):\n",
    "        \n",
    "        ind = -1\n",
    "        \n",
    "        q_list = []\n",
    "        for layer in self.features:\n",
    "            if isinstance(layer, nn.Conv2d):\n",
    "                ind += 1\n",
    "                q_list.append(Quantize('conv', layer, quant_nums[ind], quick))\n",
    "                print('Done', ind)\n",
    "            else:\n",
    "                q_list.append(layer)\n",
    "        self.features = nn.Sequential(*q_list)\n",
    "        \n",
    "        q_list = []\n",
    "        for layer in self.classifier:\n",
    "            if isinstance(layer, nn.Linear):\n",
    "                ind += 1\n",
    "                q_list.append(Quantize('fc', layer, quant_nums[ind], quick))\n",
    "                print('Done', ind)\n",
    "            else:\n",
    "                q_list.append(layer)\n",
    "        self.classifier = nn.Sequential(*q_list)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = self.avgpool(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "    \n",
    "    def un_quantize(self):\n",
    "        q_list = []\n",
    "        for layer in self.features:\n",
    "            if isinstance(layer, Quantize):\n",
    "                vals = torch.squeeze(layer.centroids[layer.labels], dim = -1).type(torch.float32)\n",
    "                wt = torch.zeros(layer.wt_shape, dtype = torch.float32).to(device)\n",
    "                wt[layer.mask] = vals\n",
    "                my_layer = nn.Conv2d(wt.shape[1], wt.shape[0], kernel_size = wt.shape[2], stride = layer.stride, padding = layer.padding, dilation = layer.dilation, groups = layer.groups)\n",
    "                my_layer.weight.data.copy_(wt)\n",
    "                my_layer.bias.data.copy_(layer.bias)\n",
    "                q_list.append(my_layer)\n",
    "            else:\n",
    "                q_list.append(layer)\n",
    "        self.features = nn.Sequential(*q_list)\n",
    "        \n",
    "        q_list = []\n",
    "        for layer in self.classifier:\n",
    "            if isinstance(layer, Quantize):\n",
    "                vals = torch.squeeze(layer.centroids[layer.labels], dim = -1).type(torch.float32)\n",
    "                wt = torch.zeros(layer.wt_shape, dtype = torch.float32).to(device)\n",
    "                wt[layer.mask] = vals\n",
    "                my_layer = nn.Linear(wt.shape[1], wt.shape[0])\n",
    "                my_layer.weight.data.copy_(wt)\n",
    "                my_layer.bias.data.copy_(layer.bias)\n",
    "                q_list.append(my_layer)\n",
    "            else:\n",
    "                q_list.append(layer)\n",
    "        self.classifier = nn.Sequential(*q_list)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_accuracy(model, phase, record_grad, criterion = None, optimizer = None, I = None):\n",
    "    \n",
    "    global device\n",
    "    \n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "#     if record_grad:\n",
    "#         model.train()\n",
    "#     else:\n",
    "#         model.eval()\n",
    "\n",
    "        \n",
    "    done = 0\n",
    "    acc = 0.0\n",
    "    since = time.time()\n",
    "    corrects = torch.tensor(0)\n",
    "    total_loss = 0.0\n",
    "    corrects = corrects.to(device)\n",
    "    loss = 100.0\n",
    "    \n",
    "    if I == None:\n",
    "        for inputs, labels in dataloader[phase]:\n",
    "\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            if record_grad:\n",
    "                with torch.set_grad_enabled(True):\n",
    "                    optimizer.zero_grad()\n",
    "                    outputs = model(inputs)\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "                    corrects += torch.sum(preds == labels)\n",
    "                    loss = criterion(outputs, labels)\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "\n",
    "                total_loss += loss.item() * inputs.size(0)\n",
    "\n",
    "            else:\n",
    "                with torch.set_grad_enabled(False):\n",
    "                    outputs = model(inputs)\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "                    corrects += torch.sum(preds == labels)\n",
    "                    \n",
    "            done += len(inputs)\n",
    "            print('\\r{}, {}, {:.2f}%, {:.2f}'.format(corrects.item(), done, corrects.item() * 100.0 / done, total_loss), end = '')\n",
    "#             if done >= 64:\n",
    "#                 break\n",
    "                    \n",
    "    else:\n",
    "            \n",
    "        inputs, labels = I\n",
    "\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        if record_grad:\n",
    "            with torch.set_grad_enabled(True):\n",
    "                optimizer.zero_grad()\n",
    "                outputs = model(inputs)\n",
    "                _, preds = torch.max(outputs, 1)\n",
    "                corrects += torch.sum(preds == labels)\n",
    "                loss = criterion(outputs, labels)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                #print(model.features[0].centroids.grad)\n",
    "            total_loss += loss.item() * inputs.size(0)\n",
    "\n",
    "        else:\n",
    "            with torch.set_grad_enabled(False):\n",
    "                outputs = model(inputs)\n",
    "                _, preds = torch.max(outputs, 1)\n",
    "                corrects += torch.sum(preds == labels)\n",
    "                \n",
    "        done += len(inputs)\n",
    "        print('\\r{}, {}, {:.2f}%, {:.2f}'.format(corrects.item(), done, corrects.item() * 100.0 / done, total_loss), end = '')\n",
    "\n",
    "    acc = corrects.double() / done\n",
    "    print('\\n{} Acc: {:.4f} %'.format(phase, acc * 100))\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print('Total time taken = {} seconds'.format(time_elapsed))\n",
    "\n",
    "    if record_grad:\n",
    "        return acc, total_loss\n",
    "    else:\n",
    "        return acc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_limited(model, criterion, optimizer, scheduler = None, num_epochs = 25, I = None, do_baseline = True):\n",
    "    \n",
    "    global device\n",
    "    global SAVE_PATH\n",
    "    \n",
    "    print('          ', end = '\\r')\n",
    "    acc = {'train':0.0, 'val':0.0}\n",
    "    best_acc = 0.0\n",
    "    \n",
    "    if do_baseline:\n",
    "        acc['train'] = check_accuracy(model, phase = 'train', record_grad = False)\n",
    "        print('.......... Baseline Evaluation Done ..............')\n",
    "        best_acc = acc['train']\n",
    "    \n",
    "    since = time.time()\n",
    "    torch.save(model.state_dict(), SAVE_PATH)\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "        print('-' * 10)\n",
    "        \n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'val':\n",
    "                epoch_acc = check_accuracy(model, 'train', record_grad = False, I = I)\n",
    "                if epoch_acc > best_acc:\n",
    "                    print('Saving')\n",
    "                    best_acc = epoch_acc\n",
    "                    torch.save(model.state_dict(), SAVE_PATH)\n",
    "            else:\n",
    "                epoch_acc, epoch_loss = check_accuracy(model, 'train', criterion=criterion, optimizer=optimizer, record_grad = True, I = I)\n",
    "                \n",
    "        print()\n",
    "        \n",
    "        if scheduler != None:\n",
    "            scheduler.step()\n",
    "        \n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n",
    "    print('Best val Acc: {:4f}'.format(best_acc))\n",
    "    \n",
    "    model.load_state_dict(torch.load(SAVE_PATH))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, criterion, optimizer, scheduler = None, num_epochs = 25, I = None, do_baseline = True):\n",
    "    \n",
    "    global device\n",
    "    global SAVE_PATH\n",
    "    \n",
    "    print('          ', end = '\\r')\n",
    "    acc = {'train':0.0, 'val':0.0}\n",
    "    best_acc = 0.0\n",
    "    \n",
    "    if do_baseline:\n",
    "        acc['val'] = check_accuracy(model, phase = 'val', record_grad = False)\n",
    "        acc['train'] = check_accuracy(model, phase = 'train', record_grad = False)\n",
    "        print('.......... Baseline Evaluation Done ..............')\n",
    "        best_acc = acc['val']\n",
    "    \n",
    "    since = time.time()\n",
    "    torch.save(model.state_dict(), SAVE_PATH)\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "        print('-' * 10)\n",
    "        \n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'val':\n",
    "                epoch_acc = check_accuracy(model, phase, record_grad = False, I = I)\n",
    "                if epoch_acc > best_acc:\n",
    "                    print('Saving')\n",
    "                    best_acc = epoch_acc\n",
    "                    torch.save(model.state_dict(), SAVE_PATH)\n",
    "            else:\n",
    "                epoch_acc, epoch_loss = check_accuracy(model, phase, criterion=criterion, optimizer=optimizer, record_grad = True, I = I)\n",
    "                \n",
    "        print()\n",
    "        \n",
    "        if scheduler != None:\n",
    "            scheduler.step()\n",
    "        \n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n",
    "    print('Best val Acc: {:4f}'.format(best_acc))\n",
    "    \n",
    "    model.load_state_dict(torch.load(SAVE_PATH))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19271, 40000, 48.18%, 0.00\n",
      "train Acc: 48.1775 %\n",
      "Total time taken = 24.76977825164795 seconds\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(0.4818, device='cuda:0', dtype=torch.float64)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda')\n",
    "model = models.alexnet(pretrained=True)\n",
    "check_accuracy(model, 'train', record_grad = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19079, 40000, 47.70%, 0.00\n",
      "train Acc: 47.6975 %\n",
      "Total time taken = 24.577978372573853 seconds\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(0.4770, device='cuda:0', dtype=torch.float64)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load('../models/undone_pruned_net.pth'))\n",
    "model.to(device)\n",
    "check_accuracy(model, 'train', record_grad = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done 0\n",
      "Done 1\n",
      "Done 2\n",
      "Done 3\n",
      "Done 4\n",
      "Done 5\n",
      "Done 6\n",
      "Done 7\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ORIG_PATH = '../models/NNA_quants.pth'\n",
    "\n",
    "# model = AlexNet(init_model=alexnet, quant_nums_w = [32]*8, quick = False)\n",
    "# torch.save(model.state_dict(), ORIG_PATH)\n",
    "\n",
    "model = AlexNet(init_model=model, quant_nums_w = [32]*8, quick = True)\n",
    "#model.load_state_dict(torch.load(ORIG_PATH))\n",
    "model.load_state_dict(torch.load(SAVE_PATH))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8 [Parameter containing:\n",
      "tensor([[-0.0304],\n",
      "        [ 0.1038],\n",
      "        [-0.1847],\n",
      "        [ 0.3390],\n",
      "        [ 0.0443],\n",
      "        [-0.3106],\n",
      "        [ 0.1667],\n",
      "        [-0.1163],\n",
      "        [-0.6406],\n",
      "        [ 0.4367],\n",
      "        [-0.4331],\n",
      "        [-0.0665],\n",
      "        [ 0.0150],\n",
      "        [ 0.2522],\n",
      "        [ 0.6203],\n",
      "        [-0.2628],\n",
      "        [ 0.0616],\n",
      "        [ 0.1319],\n",
      "        [-0.0158],\n",
      "        [ 0.2086],\n",
      "        [-0.0890],\n",
      "        [ 0.8414],\n",
      "        [-0.1482],\n",
      "        [ 0.0288],\n",
      "        [-0.3729],\n",
      "        [-0.2239],\n",
      "        [-0.0470],\n",
      "        [ 0.5087],\n",
      "        [-0.5059],\n",
      "        [ 0.0815],\n",
      "        [ 0.2964],\n",
      "        [ 0.3867]], device='cuda:0', requires_grad=True), Parameter containing:\n",
      "tensor([[-0.0291],\n",
      "        [ 0.0409],\n",
      "        [-0.0799],\n",
      "        [ 0.2527],\n",
      "        [-0.2078],\n",
      "        [ 0.0216],\n",
      "        [ 0.0996],\n",
      "        [-0.4167],\n",
      "        [-0.0501],\n",
      "        [ 2.1189],\n",
      "        [-0.1180],\n",
      "        [-0.0126],\n",
      "        [ 0.0795],\n",
      "        [ 0.6553],\n",
      "        [ 0.1579],\n",
      "        [-0.2571],\n",
      "        [ 0.4386],\n",
      "        [ 0.0130],\n",
      "        [-0.1701],\n",
      "        [-0.0639],\n",
      "        [ 0.0516],\n",
      "        [-0.6178],\n",
      "        [-0.0385],\n",
      "        [-0.1413],\n",
      "        [ 0.3303],\n",
      "        [ 0.0309],\n",
      "        [ 0.1998],\n",
      "        [ 0.0638],\n",
      "        [-0.0978],\n",
      "        [ 0.1255],\n",
      "        [-0.0207],\n",
      "        [-0.3226]], device='cuda:0', requires_grad=True), Parameter containing:\n",
      "tensor([[ 0.0183],\n",
      "        [-0.0281],\n",
      "        [-0.1227],\n",
      "        [ 0.0527],\n",
      "        [-0.0535],\n",
      "        [ 0.1405],\n",
      "        [-0.0169],\n",
      "        [ 0.0369],\n",
      "        [ 0.0731],\n",
      "        [-0.0615],\n",
      "        [-0.2121],\n",
      "        [-0.0825],\n",
      "        [ 0.2871],\n",
      "        [ 0.0298],\n",
      "        [-0.0397],\n",
      "        [ 0.1100],\n",
      "        [-0.0114],\n",
      "        [-0.0989],\n",
      "        [ 0.0104],\n",
      "        [ 0.0446],\n",
      "        [ 0.0884],\n",
      "        [-0.0224],\n",
      "        [-0.3316],\n",
      "        [ 0.1887],\n",
      "        [ 0.5149],\n",
      "        [ 0.0617],\n",
      "        [-0.1577],\n",
      "        [-0.0462],\n",
      "        [ 0.0140],\n",
      "        [ 0.0235],\n",
      "        [-0.0707],\n",
      "        [-0.0337]], device='cuda:0', requires_grad=True), Parameter containing:\n",
      "tensor([[ 0.0344],\n",
      "        [-0.0246],\n",
      "        [-0.0630],\n",
      "        [ 0.0153],\n",
      "        [ 0.0675],\n",
      "        [-0.0135],\n",
      "        [-0.0429],\n",
      "        [ 0.0487],\n",
      "        [-0.1110],\n",
      "        [ 0.1146],\n",
      "        [ 0.0243],\n",
      "        [-0.0329],\n",
      "        [-0.0865],\n",
      "        [-0.0169],\n",
      "        [ 0.2040],\n",
      "        [ 0.0409],\n",
      "        [-0.2506],\n",
      "        [ 0.0109],\n",
      "        [-0.0488],\n",
      "        [-0.1653],\n",
      "        [ 0.0944],\n",
      "        [-0.0376],\n",
      "        [ 0.0198],\n",
      "        [ 0.0574],\n",
      "        [-0.0286],\n",
      "        [ 0.0795],\n",
      "        [-0.0554],\n",
      "        [ 0.0290],\n",
      "        [-0.0726],\n",
      "        [-0.0103],\n",
      "        [-0.0207],\n",
      "        [ 0.1448]], device='cuda:0', requires_grad=True), Parameter containing:\n",
      "tensor([[ 0.0205],\n",
      "        [-0.0293],\n",
      "        [ 0.0523],\n",
      "        [-0.0628],\n",
      "        [-0.0176],\n",
      "        [ 0.0342],\n",
      "        [-0.0395],\n",
      "        [ 0.0960],\n",
      "        [-0.0104],\n",
      "        [ 0.0136],\n",
      "        [-0.0858],\n",
      "        [ 0.0688],\n",
      "        [ 0.0398],\n",
      "        [-0.0499],\n",
      "        [ 0.0246],\n",
      "        [ 0.1590],\n",
      "        [-0.0140],\n",
      "        [-0.0250],\n",
      "        [ 0.0104],\n",
      "        [-0.0342],\n",
      "        [ 0.0290],\n",
      "        [-0.0725],\n",
      "        [ 0.0597],\n",
      "        [-0.0448],\n",
      "        [-0.0556],\n",
      "        [-0.1385],\n",
      "        [-0.1052],\n",
      "        [ 0.0459],\n",
      "        [ 0.0804],\n",
      "        [-0.0213],\n",
      "        [ 0.0169],\n",
      "        [ 0.1186]], device='cuda:0', requires_grad=True), Parameter containing:\n",
      "tensor([[ 0.0091],\n",
      "        [-0.0128],\n",
      "        [ 0.0210],\n",
      "        [-0.0208],\n",
      "        [ 0.0159],\n",
      "        [-0.0101],\n",
      "        [ 0.0124],\n",
      "        [-0.0164],\n",
      "        [ 0.0362],\n",
      "        [-0.0330],\n",
      "        [-0.0256],\n",
      "        [ 0.0235],\n",
      "        [ 0.0115],\n",
      "        [-0.0175],\n",
      "        [ 0.0190],\n",
      "        [-0.0145],\n",
      "        [-0.0110],\n",
      "        [ 0.0265],\n",
      "        [ 0.0134],\n",
      "        [-0.0190],\n",
      "        [-0.0230],\n",
      "        [ 0.0106],\n",
      "        [-0.0288],\n",
      "        [ 0.0146],\n",
      "        [-0.0092],\n",
      "        [-0.0402],\n",
      "        [ 0.0303],\n",
      "        [-0.0154],\n",
      "        [ 0.0174],\n",
      "        [-0.0119],\n",
      "        [ 0.0099],\n",
      "        [-0.0136]], device='cuda:0', requires_grad=True), Parameter containing:\n",
      "tensor([[ 0.0153],\n",
      "        [-0.0115],\n",
      "        [-0.0188],\n",
      "        [ 0.0264],\n",
      "        [-0.0283],\n",
      "        [ 0.0098],\n",
      "        [-0.0143],\n",
      "        [ 0.0214],\n",
      "        [-0.0349],\n",
      "        [ 0.0368],\n",
      "        [-0.0222],\n",
      "        [ 0.0324],\n",
      "        [-0.0091],\n",
      "        [ 0.0126],\n",
      "        [ 0.0191],\n",
      "        [-0.0129],\n",
      "        [-0.0259],\n",
      "        [-0.0172],\n",
      "        [-0.0399],\n",
      "        [ 0.0239],\n",
      "        [-0.0312],\n",
      "        [ 0.0170],\n",
      "        [-0.0490],\n",
      "        [-0.0205],\n",
      "        [ 0.0112],\n",
      "        [ 0.0507],\n",
      "        [ 0.0291],\n",
      "        [-0.0157],\n",
      "        [ 0.0139],\n",
      "        [ 0.0424],\n",
      "        [-0.0239],\n",
      "        [-0.0103]], device='cuda:0', requires_grad=True), Parameter containing:\n",
      "tensor([[-0.0203],\n",
      "        [ 0.0261],\n",
      "        [ 0.0143],\n",
      "        [ 0.0585],\n",
      "        [-0.0375],\n",
      "        [-0.0123],\n",
      "        [ 0.0411],\n",
      "        [ 0.0775],\n",
      "        [-0.0258],\n",
      "        [ 0.0200],\n",
      "        [ 0.0331],\n",
      "        [-0.0512],\n",
      "        [ 0.0097],\n",
      "        [ 0.0515],\n",
      "        [-0.0149],\n",
      "        [ 0.1376],\n",
      "        [ 0.1065],\n",
      "        [-0.0328],\n",
      "        [ 0.0171],\n",
      "        [-0.0644],\n",
      "        [ 0.0672],\n",
      "        [-0.0230],\n",
      "        [-0.0098],\n",
      "        [-0.0433],\n",
      "        [ 0.0295],\n",
      "        [-0.0290],\n",
      "        [ 0.0229],\n",
      "        [-0.0176],\n",
      "        [ 0.0118],\n",
      "        [ 0.0900],\n",
      "        [ 0.0369],\n",
      "        [ 0.0459]], device='cuda:0', requires_grad=True)]\n"
     ]
    }
   ],
   "source": [
    "params = list(filter(lambda p: p.requires_grad, model.parameters()))\n",
    "print(len(params), params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18714, 40000, 46.78%, 0.00\n",
      "train Acc: 46.7850 %\n",
      "Total time taken = 27.968446969985962 seconds\n",
      ".......... Baseline Evaluation Done ..............\n",
      "Epoch 0/99\n",
      "----------\n",
      "18796, 40000, 46.99%, 97743.12\n",
      "train Acc: 46.9900 %\n",
      "Total time taken = 92.58258867263794 seconds\n",
      "18791, 40000, 46.98%, 0.00\n",
      "train Acc: 46.9775 %\n",
      "Total time taken = 28.590837240219116 seconds\n",
      "Saving\n",
      "\n",
      "Epoch 1/99\n",
      "----------\n",
      "18826, 40000, 47.06%, 97957.89\n",
      "train Acc: 47.0650 %\n",
      "Total time taken = 91.80765104293823 seconds\n",
      "18711, 40000, 46.78%, 0.00\n",
      "train Acc: 46.7775 %\n",
      "Total time taken = 27.66166114807129 seconds\n",
      "\n",
      "Epoch 2/99\n",
      "----------\n",
      "18777, 40000, 46.94%, 98287.92\n",
      "train Acc: 46.9425 %\n",
      "Total time taken = 92.3066155910492 seconds\n",
      "18825, 40000, 47.06%, 0.00\n",
      "train Acc: 47.0625 %\n",
      "Total time taken = 28.00094509124756 seconds\n",
      "Saving\n",
      "\n",
      "Epoch 3/99\n",
      "----------\n",
      "18772, 40000, 46.93%, 98172.43\n",
      "train Acc: 46.9300 %\n",
      "Total time taken = 91.87693190574646 seconds\n",
      "18777, 40000, 46.94%, 0.00\n",
      "train Acc: 46.9425 %\n",
      "Total time taken = 27.88569664955139 seconds\n",
      "\n",
      "Epoch 4/99\n",
      "----------\n",
      "18774, 40000, 46.94%, 98119.27\n",
      "train Acc: 46.9350 %\n",
      "Total time taken = 94.10027647018433 seconds\n",
      "18814, 40000, 47.03%, 0.00\n",
      "train Acc: 47.0350 %\n",
      "Total time taken = 29.123061418533325 seconds\n",
      "\n",
      "Epoch 5/99\n",
      "----------\n",
      "18797, 40000, 46.99%, 97936.28\n",
      "train Acc: 46.9925 %\n",
      "Total time taken = 95.0971987247467 seconds\n",
      "18760, 40000, 46.90%, 0.00\n",
      "train Acc: 46.9000 %\n",
      "Total time taken = 28.741185665130615 seconds\n",
      "\n",
      "Epoch 6/99\n",
      "----------\n",
      "15728, 33280, 47.26%, 80968.25"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-8ebb0b8f79ae>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mI\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_limited\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexp_lr_scheduler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mI\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mI\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdo_baseline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-11-76cf00748cf2>\u001b[0m in \u001b[0;36mtrain_limited\u001b[0;34m(model, criterion, optimizer, scheduler, num_epochs, I, do_baseline)\u001b[0m\n\u001b[1;32m     28\u001b[0m                     \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSAVE_PATH\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m                 \u001b[0mepoch_acc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_accuracy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'train'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecord_grad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mI\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mI\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-10-2147d88133d7>\u001b[0m in \u001b[0;36mcheck_accuracy\u001b[0;34m(model, phase, record_grad, criterion, optimizer, I)\u001b[0m\n\u001b[1;32m     32\u001b[0m                     \u001b[0mcorrects\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreds\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m                     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m                     \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m                     \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/Default/lib/python3.7/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    196\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m         \"\"\"\n\u001b[0;32m--> 198\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    199\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/Default/lib/python3.7/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     98\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     99\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.to(device)\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "criterion = nn.CrossEntropyLoss() \n",
    "params = filter(lambda p: p.requires_grad, model.parameters())\n",
    "optimizer = optim.SGD(params, lr = 1e-7, momentum = 0.9)\n",
    "#exp_lr_scheduler = lr_scheduler.StepLR(optimizer, step_size = 5, gamma = 0.5)\n",
    "exp_lr_scheduler = None\n",
    "#I = next(iter(dataloader['train']))\n",
    "I = None\n",
    "\n",
    "model = train_limited(model, criterion, optimizer, exp_lr_scheduler, num_epochs = 100, I = I, do_baseline = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18786, 40000, 46.97%, 0.00\n",
      "train Acc: 46.9650 %\n",
      "Total time taken = 28.752476453781128 seconds\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(0.4697, device='cuda:0', dtype=torch.float64)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load(SAVE_PATH))\n",
    "model.to(device)\n",
    "check_accuracy(model, 'train', record_grad = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.un_quantize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Conv2d(3, 64, kernel_size=(11, 11), stride=(4, 4), padding=(2, 2))\n",
       "  (1): ReLU(inplace=True)\n",
       "  (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (3): Conv2d(64, 192, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "  (4): ReLU(inplace=True)\n",
       "  (5): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (6): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (7): ReLU(inplace=True)\n",
       "  (8): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (9): ReLU(inplace=True)\n",
       "  (10): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (11): ReLU(inplace=True)\n",
       "  (12): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       ")"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Dropout(p=0.5, inplace=False)\n",
       "  (1): Linear(in_features=9216, out_features=4096, bias=True)\n",
       "  (2): ReLU(inplace=True)\n",
       "  (3): Dropout(p=0.5, inplace=False)\n",
       "  (4): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "  (5): ReLU(inplace=True)\n",
       "  (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18741, 40000, 46.85%, 0.00\n",
      "train Acc: 46.8525 %\n",
      "Total time taken = 24.960099935531616 seconds\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(0.4685, device='cuda:0', dtype=torch.float64)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.to(device)\n",
    "check_accuracy(model, 'train', record_grad = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), '../models/undone_wt_shared_net.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####################################################################################################################\n",
    "####################################################################################################################\n",
    "####################################################################################################################\n",
    "####################################################################################################################\n",
    "####################################################################################################################\n",
    "####################################################################################################################\n",
    "####################################################################################################################\n",
    "####################################################################################################################\n",
    "####################################################################################################################\n",
    "####################################################################################################################"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
